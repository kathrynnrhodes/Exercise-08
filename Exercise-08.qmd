---
title: "Exercise-08"
format: html
editor: visual
---

Exercise 08 Answers

Step 1.

```{r}
#| warning: false
#| message: false
library(tidyverse)
library(broom)
library(skimr)
library(kableExtra)
url <- "https://raw.githubusercontent.com/difiore/ada-datasets/main/Street_et_al_2017.csv"
d <- read.csv(url, header = TRUE)
skim(d) |>
  kable() |>
  kable_styling(font_size = 10, full_width = FALSE)
detach(package:kableExtra)
detach(package:skimr)
```

Step 2. Plotting ECV

```{r}
#| warning: false
#| message: false
library(cowplot)
p1 <- ggplot(data = d, aes(x=Group_size, y=ECV)) + geom_point()
p2 <- ggplot(data = d, aes(x=Longevity, y=ECV)) + geom_point()
p3 <- ggplot(data = d, aes(x=Weaning, y=ECV)) + geom_point()
p4 <- ggplot(data = d, aes(x=Repro_lifespan, y=ECV)) + geom_point()
plot_grid(p1, p2, p3, p4, nrow = 2)
```

Step 3. Derive by hand ordinary least squares regression coefficients $\beta1$ and $\beta0$ for ECV as a function of social group size.
```{r}
d_mod <- d |> filter(!is.na(ECV) & !is.na(Group_size))
(b1 <- cor(d_mod$ECV, d_mod$Group_size) * sd(d_mod$ECV)/sd(d_mod$Group_size))
(b0 <- mean(d_mod$ECV) - b1 * mean(d_mod$Group_size))
```

$\beta1$: 2.463071
$\beta0$: 30.35652

Step 4. Confirm with lm() function
```{r}
m <- lm(ECV ~ Group_size, data = d_mod)
results <- m |>
  summary() |>
  tidy()
results
```

lm() results equal the rounded up values found in Step 03 so these $\beta1$ and $\beta0$ values are confirmed.

Step 5. Repeat the analysis above for "catarrhines", "platyrrhines", and "strepsirhines"
```{r}
platyrrhini <- d_mod |> filter(Taxonomic_group == "Platyrrhini")
catarrhini <- d_mod |> filter(Taxonomic_group == "Catarrhini")
strepsirhini <- d_mod |> filter(Taxonomic_group == "Strepsirhini")

(platyrrhini_results <- lm(ECV ~ Group_size, data = platyrrhini) |>
  summary() |>
  tidy())
(catarrhini_results <- lm(ECV ~ Group_size, data = catarrhini) |>
  summary() |>
  tidy())
(strepsirhini_results <- lm(ECV ~ Group_size, data = strepsirhini) |>
  summary() |>
  tidy())
```

The coefficients are different between groups. To see if this is significant, I'm going to randomly permute group assignments and calculate the difference in slopes between pairs of groups to create permutation distributions. I'll be able to compare the observed difference in slopes between groups to the "expected" distribution under the null model.

Step 6. Calculate the standard error for the slope coefficient, the 95% CI, and the p value associated with this coefficient by hand for regression of ECV on social group size.
```{r}
alpha <- 0.05
p.lower <- alpha/2
p.upper <- 1 - (alpha/2)
n <- nrow(d_mod) # number of observations
df <- n - 2
residuals <- d_mod$ECV - (b0 + b1 * d_mod$Group_size)
SSE <- sum(residuals^2)
dfe <- nrow(d_mod) - 1 - 1 # number of observations - number of predictors - 1 = n - p - 1
MSE <- SSE/dfe
SSX <- sum((d_mod$Group_size - mean(d_mod$Group_size))^2) 
(SE_b1 <- sqrt(MSE/SSX))
(SE_b0 <- SE_b1 * sqrt(sum(d_mod$Group_size^2)/n))
(CI_b1 <- b1 + c(-1, 1) * qt(p = 1 - (alpha/2), df = df) * SE_b1)
(CI_b0 <- b0 + c(-1, 1) * qt(p = 1 - (alpha/2), df = df) * SE_b0)
t_b1 = b1/SE_b1
t_b0 = b0/SE_b0
(p_b1 <- pt(-1 * abs(t_b1), df = df, lower.tail = TRUE) + (1 - pt(abs(t_b1), df = df, lower.tail = TRUE)))
# comparing to lm()
(results <- m |>
  summary() |>
  tidy(conf.int = TRUE, conf.level = 1 - alpha))
```

Step 7. Permutation approach
```{r}
#| warning: false
#| message: false
library(mosaic)
library(infer)
library(latticeExtra)
nperm <- 1000
perm <- vector(length = nperm)
perm.sample <- d_mod
for (i in 1:nperm){
  perm.sample$Group_size <- sample(perm.sample$Group_size)
  result <- lm(ECV ~ Group_size, data = perm.sample) |>
    tidy() |>
    filter(term == "Group_size") |>
    pull(estimate)
  perm[[i]] <- result
}
histogram(perm, xlim = c(-3,3))
ladd(panel.abline(v = b1, lty = 3, lwd = 2))
perm.se <- sd(perm)
perm <- d_mod |>
  specify(ECV ~ Group_size) |>
  hypothesize(null = "independence") |>
  generate(reps = nperm, type = "permute") |>
  calculate(stat = "slope")
visualize(perm) + shade_p_value(obs_stat = b1, direction = "two_sided")
perm.se <- sd(perm$stat)
```

P value for original slope coefficient

```{r}
(p.percentile <- perm |> 
  mutate(test = abs(stat) >= abs(b1)) |>
  summarize(p = mean(test)) |>
  pull(p))

```

P value is zero. 

Step 8. Bootstrapping
```{r}
nboot <- 1000
boot <- vector(length = nboot)
for (i in 1:nboot){
  boot.sample <- sample_n(d_mod, nrow(d_mod), replace = TRUE)
  result <- lm(ECV ~ Group_size, data = boot.sample) |>
    tidy() |>
    filter(term == "Group_size") |>
    pull(estimate)
  boot[[i]] <- result
}
histogram(boot, xlim=c(b1-3, b1+3))
CI.quantile <- c(quantile(boot, p.lower), quantile(boot, p.upper))
ladd(panel.abline(v = CI.quantile, lty = 3, lwd = 2, col = "hotpink"))
CI.theory <- b1 + c(-1, 1) * qt(p.upper, df = df) * sd(boot)
ladd(panel.abline(v = CI.theory, lty = 3, lwd = 2, col = "lightblue"))

```

None of these estimated CIs include zero, so slope coefficient estimated in our linear model is significant :)

```{r include=FALSE}
detach(package:infer)
detach(package:mosaic)
detach(package:cowplot)
detach(package:broom)
detach(package:tidyverse)

```

